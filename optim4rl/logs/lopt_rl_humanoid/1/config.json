{
  "env": {
    "name": "humanoid",
    "train_steps": 100000000.0,
    "episode_length": 1000,
    "action_repeat": 1,
    "reward_scaling": 0.1,
    "num_envs": 2048,
    "num_evals": 10,
    "normalize_obs": true
  },
  "agent": {
    "name": "PPO",
    "gae_lambda": 0.95,
    "rollout_steps": 10,
    "num_minibatches": 32,
    "clipping_epsilon": 0.3,
    "update_epochs": 8,
    "entropy_weight": 0.001,
    "inner_updates": 0
  },
  "optim": {
    "name": "Optim4RL",
    "kwargs": {
      "param_load_path": "./logs/meta_rl_humanoid/1/param.pickle",
      "learning_rate": 0.0003,
      "grad_clip": 1
    }
  },
  "batch_size": 1024,
  "discount": 0.97,
  "max_devices_per_host": -1,
  "seed": 759025,
  "generate_random_seed": true,
  "config_idx": 1,
  "num_combinations": 50,
  "save_param": 0,
  "exp": "lopt_rl_humanoid",
  "logs_dir": "./logs/lopt_rl_humanoid/1/",
  "model_path": "./logs/lopt_rl_humanoid/1/model.pt",
  "cfg_path": "./logs/lopt_rl_humanoid/1/config.json"
}